{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d920d67",
   "metadata": {},
   "source": [
    "## We will do the sanity check for the visual encoders we implemented\n",
    "We will use CIFAR 10 to do image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d4fd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zihan/bimaminobolonana'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we get the path\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent.absolute()))\n",
    "os.chdir(\"..\") # change to repo root dir\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5b16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = CIFAR10(root=\"data\", train=True, download=True)\n",
    "test_data  = CIFAR10(root=\"data\", train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356a1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/zihan/bimaminobolonana/encoder/pri3d.py:88: UserWarning: Pri3D ckpt loaded from '/home/zihan/Downloads/ScanNet_Combine_BatchSize64_LearningRate01_Epoch5_ImageSize240x320_ResNet50.pth': matched=318, missing=0, unexpected=455\n",
      "  warnings.warn(f\"Pri3D ckpt loaded from '{ckpt_path}': matched={matched}, missing={len(missing)}, unexpected={len(unexpected)}\")\n"
     ]
    }
   ],
   "source": [
    "# Load the encoders\n",
    "import yaml\n",
    "from encoder import build_encoder\n",
    "\n",
    "def load_encoder(cfg_path):\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    encoder = build_encoder(cfg).eval().cuda()\n",
    "    return encoder\n",
    "\n",
    "encoders = {\n",
    "    \"Pri3D (pretrained)\": load_encoder(\"configs/encoder_pri3d_pretrained.yaml\"),\n",
    "    \"CLIP ViT-B/32\": load_encoder(\"configs/encoder_clip_b32_openai.yaml\"),\n",
    "    \"Pri3D (untrained)\": load_encoder(\"configs/encoder_pri3d_random.yaml\"),\n",
    "    \"CLIP ViT-B/32 (untrained)\": load_encoder(\"configs/encoder_clip_b32.yaml\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0442f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_for_encoder(encoder_name: str):\n",
    "    if \"clip\" in encoder_name.lower():\n",
    "        return T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "                        std=(0.26862954, 0.26130258, 0.27577711))\n",
    "        ])\n",
    "    else:\n",
    "        # Pri3D, untrained, or custom encoders\n",
    "        return T.Compose([\n",
    "            T.Resize((128, 128)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b6be",
   "metadata": {},
   "source": [
    "### Then we perform the feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6476c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(encoder, loader):\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y in tqdm(loader):\n",
    "            imgs = imgs.cuda()\n",
    "            out = encoder.encode((imgs, imgs))  # same img both sides (mono-view)\n",
    "            fused = out[\"fused\"]\n",
    "            feats.append(fused.cpu())\n",
    "            labels.append(y)\n",
    "    return torch.cat(feats), torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ae87a",
   "metadata": {},
   "source": [
    "### Using Frozen Features, we train a simple linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7b595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On frozen features, train a simple classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_encoder(name, encoder, train_data, test_data):\n",
    "    print(f\"\\n==> Evaluating {name}\")\n",
    "    \n",
    "    tfm = get_transform_for_encoder(name)\n",
    "    train_data.transform = tfm\n",
    "    test_data.transform  = tfm\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "    test_loader  = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n",
    "    \n",
    "    X_train, y_train = extract_features(encoder, train_loader)\n",
    "    X_test,  y_test  = extract_features(encoder, test_loader)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "    clf.fit(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "    acc = clf.score(X_test.numpy(), y_test.numpy())\n",
    "    print(f\"{name} Accuracy: {acc*100:.2f}%\")\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388c2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Evaluating Pri3D (pretrained)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [01:35<00:00,  8.23it/s]\n",
      "100%|██████████| 157/157 [00:19<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pri3D (pretrained) Accuracy: 73.22%\n",
      "\n",
      "==> Evaluating CLIP ViT-B/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [06:59<00:00,  1.86it/s]\n",
      "100%|██████████| 157/157 [01:25<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP ViT-B/32 Accuracy: 94.09%\n",
      "\n",
      "==> Evaluating Pri3D (untrained)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [01:42<00:00,  7.66it/s]\n",
      "100%|██████████| 157/157 [00:22<00:00,  7.06it/s]\n",
      "/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pri3D (untrained) Accuracy: 43.28%\n",
      "\n",
      "==> Evaluating CLIP ViT-B/32 (untrained)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [07:02<00:00,  1.85it/s]\n",
      "100%|██████████| 157/157 [01:28<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP ViT-B/32 (untrained) Accuracy: 47.76%\n",
      "\n",
      "=== Summary ===\n",
      "Pri3D (pretrained)        -> 73.22%\n",
      "CLIP ViT-B/32             -> 94.09%\n",
      "Pri3D (untrained)         -> 43.28%\n",
      "CLIP ViT-B/32 (untrained) -> 47.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, enc in encoders.items():\n",
    "    results[name] = evaluate_encoder(name, enc, train_data, test_data)\n",
    "\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k:25s} -> {v*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
