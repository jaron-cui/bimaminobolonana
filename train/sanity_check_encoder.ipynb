{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d920d67",
   "metadata": {},
   "source": [
    "## We will do the sanity check for the visual encoders we implemented\n",
    "We will use CIFAR 10 to do image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d4fd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zihan/bimaminobolonana'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we get the path\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent.absolute()))\n",
    "os.chdir(\"..\") # change to repo root dir\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5b16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = CIFAR10(root=\"data\", train=True, download=True)\n",
    "test_data  = CIFAR10(root=\"data\", train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356a1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pri3D] Loading pretrained weights from /home/zihan/bimaminobolonana/checkpoints/resnet50_pri3d_tv.pth\n",
      "[Pri3D] Loaded with missing=265, unexpected=318\n"
     ]
    }
   ],
   "source": [
    "# Load the encoders\n",
    "import yaml\n",
    "from encoder import build_encoder\n",
    "\n",
    "def load_encoder(cfg_path):\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    encoder = build_encoder(cfg).eval().cuda()\n",
    "    return encoder\n",
    "\n",
    "encoders = {\n",
    "    \"Pri3D (pretrained)\": load_encoder(\"configs/encoder_pri3d_pretrained.yaml\"),\n",
    "    \"CLIP ViT-B/32\": load_encoder(\"configs/encoder_clip_b32_openai.yaml\"),\n",
    "    \"Pri3D (untrained)\": load_encoder(\"configs/encoder_pri3d_random.yaml\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0442f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_for_encoder(encoder_name: str):\n",
    "    if \"clip\" in encoder_name.lower():\n",
    "        return T.Compose([\n",
    "            T.Resize((224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "                        std=(0.26862954, 0.26130258, 0.27577711))\n",
    "        ])\n",
    "    else:\n",
    "        # Pri3D, untrained, or custom encoders\n",
    "        return T.Compose([\n",
    "            T.Resize((128, 128)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225))\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b6be",
   "metadata": {},
   "source": [
    "### Then we perform the feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6476c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(encoder, loader):\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y in tqdm(loader):\n",
    "            imgs = imgs.cuda()\n",
    "            out = encoder.encode((imgs, imgs))  # same img both sides (mono-view)\n",
    "            fused = out[\"fused\"]\n",
    "            feats.append(fused.cpu())\n",
    "            labels.append(y)\n",
    "    return torch.cat(feats), torch.cat(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ae87a",
   "metadata": {},
   "source": [
    "### Using Frozen Features, we train a simple linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7b595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On frozen features, train a simple classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_encoder(name, encoder, train_data, test_data):\n",
    "    print(f\"\\n==> Evaluating {name}\")\n",
    "    \n",
    "    tfm = get_transform_for_encoder(name)\n",
    "    train_data.transform = tfm\n",
    "    test_data.transform  = tfm\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
    "    test_loader  = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n",
    "    \n",
    "    X_train, y_train = extract_features(encoder, train_loader)\n",
    "    X_test,  y_test  = extract_features(encoder, test_loader)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "    clf.fit(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "    acc = clf.score(X_test.numpy(), y_test.numpy())\n",
    "    print(f\"{name} Accuracy: {acc*100:.2f}%\")\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c2fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> Evaluating Pri3D (pretrained)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nTypeError: 'DataLoader' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, enc \u001b[38;5;129;01min\u001b[39;00m encoders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 3\u001b[0m     results[name] \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Summary ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mevaluate_encoder\u001b[0;34m(name, encoder, train_data, test_data)\u001b[0m\n\u001b[1;32m     12\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     13\u001b[0m test_loader  \u001b[38;5;241m=\u001b[39m DataLoader(test_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m X_test,  y_test  \u001b[38;5;241m=\u001b[39m extract_features(encoder, test_loader)\n\u001b[1;32m     18\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(encoder, loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m feats, labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m imgs, y \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m      9\u001b[0m         imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m         out \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode((imgs, imgs))  \u001b[38;5;66;03m# same img both sides (mono-view)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/dataloader.py:732\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    738\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1506\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1504\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1541\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dev/lib/python3.10/site-packages/torch/_utils.py:769\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 769\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/zihan/miniconda3/envs/dev/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nTypeError: 'DataLoader' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, enc in encoders.items():\n",
    "    results[name] = evaluate_encoder(name, enc, train_data, test_data)\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k:25s} -> {v*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
